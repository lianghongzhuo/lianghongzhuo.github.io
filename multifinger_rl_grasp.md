---
layout: default
title: Multifingered Grasping Based on Multimodal Reinforcement Learning
---
# Multifingered Grasping Based on Multimodal Reinforcement Learning

## Abstract
In this work, we solve the multifingered grasping problem using multimodal reinforcement learning.
The simulation and real robot experiments with dedicated initial grasping poses show that our method outperforms hard-coded closing finger motion and the agent with fewer modalities in the grasp success rate for seen and unseen objects.

PDF file can be downloaded from [here](https://ieeexplore.ieee.org/document/9664242).

## Video

<div style="text-align:center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/PuYvUxyDnPY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>


## Bibtex

```plain
@article{liang2022,
  author={Liang, Hongzhuo and Cong, Lin and Hendrich, Norman and Li, Shuang and Sun, Fuchun and Zhang, Jianwei},
  journal={IEEE Robotics and Automation Letters (RA-L)},
  title={Multifingered Grasping Based on Multimodal Reinforcement Learning},
  year={2022},
  volume={7},
  number={2},
  pages={1174-1181},
  doi={10.1109/LRA.2021.3138545}
}
```
